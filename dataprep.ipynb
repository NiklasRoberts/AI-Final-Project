{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tree measurements for year 82, 85, and 90\n",
    "import pandas as pd\n",
    "treeMeasurements = pd.read_csv(\"C55_TreeMeasurements.csv\")\n",
    "\n",
    "#getting trees from 1982 and 1985 measurements\n",
    "desiredCols1 = [\"PLOT\", \"TREE\", \"RECRUIT\", \"SPECIES\", \"D82\", \"D85\"]\n",
    "customMeasurements1 = treeMeasurements[desiredCols1]\n",
    "\n",
    "#getting trees from 1985 to 1990\n",
    "desiredCols2 = [\"PLOT\", \"TREE\", \"RECRUIT\", \"SPECIES\", \"D85\", \"D90\"]\n",
    "customMeasurements2 = treeMeasurements[desiredCols2]\n",
    "\n",
    "#cleaning data to gather trees that only have measurements at both ends of the period\n",
    "clean82_85 = customMeasurements1.dropna()\n",
    "clean85_90 = customMeasurements2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting foliar nutrients from csv file\n",
    "foliarNutrients = pd.read_csv(\"C55_FoliarNutrients.csv\")\n",
    "foliarNutrients = foliarNutrients.drop(\"REPLICATE\", axis=1)\n",
    "\n",
    "# Get foliar nutrient levels 1982\n",
    "foliarNutrients82 = foliarNutrients.loc[foliarNutrients['YEAR'] == 1982]\n",
    "\n",
    "# Get foliar nutrient levels 1985\n",
    "foliarNutrients85 = foliarNutrients.loc[foliarNutrients['YEAR'] == 1985]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add foliar nutrients to tree data \n",
    "allTreeData82_85 = pd.merge(clean82_85, foliarNutrients82, on=\"PLOT\", how=\"outer\")\n",
    "allTreeData85_90 = pd.merge(clean85_90, foliarNutrients85, on=\"PLOT\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting percent growth for each tree per year\n",
    "# perc_growth = (D85-D82)/D82\n",
    "allTreeData82_85[\"Growth\"] = (allTreeData82_85[\"D85\"]-allTreeData82_85[\"D82\"])/allTreeData82_85[\"D82\"]\n",
    "# growth_per_yr = prec_growth/85-82\n",
    "allTreeData82_85[\"Growth/yr\"] = allTreeData82_85[\"Growth\"]/3\n",
    "\n",
    "#getting percent growth for 1985-1990\n",
    "# perc_growth = (D90-D85)/D825\n",
    "allTreeData85_90[\"Growth\"] = (allTreeData85_90[\"D90\"]-allTreeData85_90[\"D85\"])/allTreeData85_90[\"D85\"]\n",
    "# growth_per_yr = prec_growth/85-82\n",
    "allTreeData85_90[\"Growth/yr\"] = allTreeData85_90[\"Growth\"]/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract relevant columns: \n",
    "relColumns = [\"SPECIES\", \"TOTN\", \"TOTP\", \"TOTK\", \"TOTS\", \"TOTCa\", \"Growth/yr\"]\n",
    "modelingData82 = allTreeData82_85[relColumns]\n",
    "modelingData85 = allTreeData85_90[relColumns]\n",
    "\n",
    "# combine dataframes to make one dataframe with all data needed\n",
    "modelingData = pd.concat([modelingData82, modelingData85], ignore_index=True)\n",
    "modelingData['id'] = modelingData.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Either jump to regression, or keep going to do classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental data analysis looking at distribution and possible binning\n",
    "import matplotlib\n",
    "\n",
    "# creating a copy of current modeling data\n",
    "modelingCopy = modelingData\n",
    "\n",
    "# Creating Histogram for percent growth per year\n",
    "bins = [0, .05, .1, .2, 50]\n",
    "modelingCopy['bins'] = pd.cut(modelingData['Growth/yr'], bins = bins, include_lowest=True)\n",
    "plotDF = modelingCopy.groupby('bins').bins.count()\n",
    "plotDF.plot(kind=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-341da69c91fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mmergeDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bin'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Growth/yr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mmergeDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bin'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Growth/yr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmergeDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bin'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1922\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mappend\u001b[1;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[0;32m   7977\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7978\u001b[0m         return (\n\u001b[1;32m-> 7979\u001b[1;33m             concat(\n\u001b[0m\u001b[0;32m   7980\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7981\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    296\u001b[0m     )\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 298\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\reshape\\concat.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    518\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m             new_data = concatenate_block_managers(\n\u001b[0m\u001b[0;32m    521\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             )\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             b = make_block(\n\u001b[1;32m---> 83\u001b[1;33m                 \u001b[0m_concatenate_join_units\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\internals\\concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[1;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[0;32m    341\u001b[0m             \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0matleast_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mconcat_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcat_compat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconcat_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mconcat_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Python38\\lib\\site-packages\\pandas\\core\\dtypes\\concat.py\u001b[0m in \u001b[0;36mconcat_compat\u001b[1;34m(to_concat, axis)\u001b[0m\n\u001b[0;32m    169\u001b[0m                 \u001b[0mto_concat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mto_concat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Getting Columns for neural network classification\n",
    "# What bin does the growth/yr fall into? that bin gets a 1, others get 0\n",
    "\n",
    "mergeDF = pd.DataFrame(columns=['id', 'bin'])\n",
    "\n",
    "# For each row in modelingData setting a bin based off how growth/year\n",
    "for index, row in modelingData.iterrows():\n",
    "    #bins: 0-0.05, 0.05+ to 0.1, 0.1+ to 0.2, 0.2+\n",
    "    if row['Growth/yr'] <= .05:\n",
    "        mergeDF.loc[index] = pd.Series({'id': index, 'bin': 0})\n",
    "    elif row['Growth/yr'] <= .1:\n",
    "        mergeDF.loc[index] = pd.Series({'id': index, 'bin': 1})\n",
    "    elif row['Growth/yr'] <= .2:\n",
    "        mergeDF.loc[index] = pd.Series({'id': index, 'bin': 2})\n",
    "    else:\n",
    "        mergeDF.loc[index] = pd.Series({'id': index, 'bin': 3})\n",
    "\n",
    "# joining data to include bin\n",
    "modelingData = pd.merge(modelingData, mergeDF, on='id', how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data ready for the Classification Neural Network\n",
    "\n",
    "# Input variables: SPECIES, TOTN, TOTP, TOTK, TOTS, TOTCa, and TOTMg (not used)\n",
    "# label: fixed bins (1 for correct bin, 0 for all others)\n",
    "classifyColumns = ['SPECIES', 'TOTN', 'TOTP', 'TOTK', 'TOTS', 'TOTCa', 'bin']\n",
    "classifyData = modelingData[classifyColumns]\n",
    "\n",
    "# for turning 'species' column into numerical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "speciesLabEncoder = LabelEncoder()\n",
    "\n",
    "# Transforms species into numerical data\n",
    "speciesNumList = speciesLabEncoder.fit_transform(classifyData['SPECIES'])\n",
    "# code for reverting: species = le.inverse_transform(label)\n",
    "# changing the species column to numerical values\n",
    "classifyData['SPECIES'] = speciesNumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into input and output data\n",
    "classifyX = classifyData.iloc[:,:6].values\n",
    "classifyY = classifyData.iloc[:,6:7].values\n",
    "\n",
    "# Transforming output into binary values\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "classifyY = ohe.fit_transform(classifyY).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "classifyX_train, classifyX_test, classifyY_train, classifyY_test = train_test_split(classifyX, classifyY, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and Compiling Neural Network for Classification\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifyModel = Sequential()\n",
    "classifyModel.add(Dense(24, input_dim=6, activation='relu'))\n",
    "classifyModel.add(Dense(24, activation='relu'))\n",
    "#trying to overfit\n",
    "classifyModel.add(Dense(36, activation='relu'))\n",
    "classifyModel.add(Dense(36, activation='relu'))\n",
    "classifyModel.add(Dense(24, activation='relu'))\n",
    "classifyModel.add(Dense(12, activation='relu'))\n",
    "classifyModel.add(Dense(4, activation='sigmoid'))\n",
    "\n",
    "classifyModel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training classification model\n",
    "training = classifyModel.fit(classifyX_train, classifyY_train, epochs=100, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing classification model\n",
    "import numpy as np\n",
    "prediction = classifyModel.predict(classifyX_test)\n",
    "\n",
    "# undoing onehot encoder\n",
    "pred = list()\n",
    "for i in range(len(prediction)):\n",
    "    pred.append(np.argmax(prediction[i]))\n",
    "test = list()\n",
    "for i in range(len(classifyY_test)):\n",
    "    test.append(np.argmax(classifyY_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining accuracy of Classification Neural Network model\n",
    "from sklearn.metrics import accuracy_score\n",
    "classifyAccuracy = accuracy_score(pred,test)\n",
    "print('Accuracy is:', classifyAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-34f9984d82c7>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  regressData['SPECIES'] = speciesNumList\n"
     ]
    }
   ],
   "source": [
    "# Getting Columns for neural network regression\n",
    "# input variables: SPECIES, TOTN, TOTP, TOTK, TOTS, TOTCa, and TOTMg (not used)\n",
    "# label: predicting growth per year\n",
    "\n",
    "regressColumns = ['SPECIES', 'TOTN', 'TOTP', 'TOTK', 'TOTS', 'TOTCa', 'Growth/yr']\n",
    "regressData = modelingData[regressColumns]\n",
    "\n",
    "# for turning 'species' column into numerical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "speciesLabEncoder = LabelEncoder()\n",
    "\n",
    "# Transforms species into numerical data\n",
    "speciesNumList = speciesLabEncoder.fit_transform(regressData['SPECIES'])\n",
    "# code for reverting: species = le.inverse_transform(label)\n",
    "# changing the species column to numerical values\n",
    "regressData['SPECIES'] = speciesNumList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler()\n",
      "MinMaxScaler()\n"
     ]
    }
   ],
   "source": [
    "# Splitting into input and output data\n",
    "regressX = regressData.iloc[:,:6].values\n",
    "regressY = regressData.iloc[:,6:7].values\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "regressY = np.reshape(regressY, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print (scaler_x.fit(regressX))\n",
    "xscale = scaler_x.transform(regressX)\n",
    "print (scaler_y.fit(regressY))\n",
    "yscale = scaler_y.transform(regressY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "regressX_train, regressX_test, regressY_train, regressY_test = train_test_split(xscale, yscale, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building and Compiling Neural Network for Regression\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "regressModel = Sequential()\n",
    "regressModel.add(Dense(12, input_dim = 6, kernel_initializer='normal', activation='relu'))\n",
    "regressModel.add(Dense(12, activation='relu'))\n",
    "regressModel.add(Dense(1, activation='linear'))\n",
    "# 6/12/12/1\n",
    "#regressModel.summary()\n",
    "loss_function = keras.losses.MeanAbsoluteError()\n",
    "regressModel.compile(loss=loss_function, optimizer='adam', metrics=['mse','mae','mape'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "178/178 [==============================] - 2s 2ms/step - loss: 0.0165 - mse: 9.0082e-04 - mae: 0.0165 - mape: 194060.5325\n",
      "Epoch 2/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0108 - mse: 6.4091e-04 - mae: 0.0108 - mape: 127674.2654\n",
      "Epoch 3/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0110 - mse: 6.6646e-04 - mae: 0.0110 - mape: 158472.7546\n",
      "Epoch 4/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0114 - mse: 7.4940e-04 - mae: 0.0114 - mape: 154091.1460\n",
      "Epoch 5/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0109 - mse: 6.5193e-04 - mae: 0.0109 - mape: 157687.2477\n",
      "Epoch 6/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0112 - mse: 7.9646e-04 - mae: 0.0112 - mape: 181556.9953\n",
      "Epoch 7/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0109 - mse: 6.1670e-04 - mae: 0.0109 - mape: 169840.2760\n",
      "Epoch 8/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0107 - mse: 5.0173e-04 - mae: 0.0107 - mape: 143608.8388\n",
      "Epoch 9/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0108 - mse: 6.8647e-04 - mae: 0.0108 - mape: 146756.1123\n",
      "Epoch 10/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0106 - mse: 4.9235e-04 - mae: 0.0106 - mape: 177367.6800\n",
      "Epoch 11/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0112 - mse: 7.3111e-04 - mae: 0.0112 - mape: 169346.7756\n",
      "Epoch 12/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0106 - mse: 5.0619e-04 - mae: 0.0106 - mape: 149049.5101\n",
      "Epoch 13/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0105 - mse: 5.7974e-04 - mae: 0.0105 - mape: 159307.3647\n",
      "Epoch 14/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 5.9243e-04 - mae: 0.0105 - mape: 157833.1154\n",
      "Epoch 15/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0108 - mse: 8.0611e-04 - mae: 0.0108 - mape: 169211.3949\n",
      "Epoch 16/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0105 - mse: 5.7924e-04 - mae: 0.0105 - mape: 193322.5794\n",
      "Epoch 17/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 6.5792e-04 - mae: 0.0104 - mape: 177408.2949\n",
      "Epoch 18/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0107 - mse: 7.5979e-04 - mae: 0.0107 - mape: 183015.5363\n",
      "Epoch 19/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.4138e-04 - mae: 0.0096 - mape: 183490.0638\n",
      "Epoch 20/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 5.2748e-04 - mae: 0.0102 - mape: 163968.4372\n",
      "Epoch 21/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 6.0312e-04 - mae: 0.0102 - mape: 169039.8009\n",
      "Epoch 22/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 5.8903e-04 - mae: 0.0101 - mape: 183404.4535\n",
      "Epoch 23/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 7.8455e-04 - mae: 0.0104 - mape: 144073.7568\n",
      "Epoch 24/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 4.8561e-04 - mae: 0.0097 - mape: 149569.1379\n",
      "Epoch 25/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 4.7561e-04 - mae: 0.0098 - mape: 158096.6821\n",
      "Epoch 26/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 5.9292e-04 - mae: 0.0099 - mape: 160415.4556\n",
      "Epoch 27/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 4.7516e-04 - mae: 0.0098 - mape: 159229.2423\n",
      "Epoch 28/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 6.4365e-04 - mae: 0.0100 - mape: 173705.1775\n",
      "Epoch 29/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 6.7868e-04 - mae: 0.0100 - mape: 173342.3730\n",
      "Epoch 30/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 7.5768e-04 - mae: 0.0103 - mape: 128779.1016\n",
      "Epoch 31/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0104 - mse: 6.1606e-04 - mae: 0.0104 - mape: 172165.8136\n",
      "Epoch 32/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 5.2370e-04 - mae: 0.0098 - mape: 194775.8364\n",
      "Epoch 33/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 4.8025e-04 - mae: 0.0099 - mape: 170492.2459\n",
      "Epoch 34/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 6.5142e-04 - mae: 0.0101 - mape: 175400.1795\n",
      "Epoch 35/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 7.2202e-04 - mae: 0.0100 - mape: 159872.8589\n",
      "Epoch 36/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0101 - mse: 6.0430e-04 - mae: 0.0101 - mape: 157395.5117\n",
      "Epoch 37/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 6.3904e-04 - mae: 0.0102 - mape: 177970.1940\n",
      "Epoch 38/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0100 - mse: 5.9130e-04 - mae: 0.0100 - mape: 155663.5072\n",
      "Epoch 39/150\n",
      "178/178 [==============================] - 1s 5ms/step - loss: 0.0102 - mse: 5.8855e-04 - mae: 0.0102 - mape: 148452.0015A: 0s - loss: 0.0102 - mse: 4.8467e-04 - mae: 0.0102 - mape: \n",
      "Epoch 40/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0097 - mse: 5.9829e-04 - mae: 0.0097 - mape: 156394.8627\n",
      "Epoch 41/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0103 - mse: 5.7977e-04 - mae: 0.0103 - mape: 152334.9008\n",
      "Epoch 42/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0101 - mse: 6.8328e-04 - mae: 0.0101 - mape: 165128.8323\n",
      "Epoch 43/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0102 - mse: 9.0430e-04 - mae: 0.0102 - mape: 165039.5345\n",
      "Epoch 44/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 5.3907e-04 - mae: 0.0099 - mape: 174714.6930\n",
      "Epoch 45/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 7.8674e-04 - mae: 0.0100 - mape: 159856.8812\n",
      "Epoch 46/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 7.1309e-04 - mae: 0.0100 - mape: 167776.8318\n",
      "Epoch 47/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0102 - mse: 8.3975e-04 - mae: 0.0102 - mape: 138197.8124\n",
      "Epoch 48/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 5.5603e-04 - mae: 0.0101 - mape: 156182.7743\n",
      "Epoch 49/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0095 - mse: 4.5790e-04 - mae: 0.0095 - mape: 172145.3665\n",
      "Epoch 50/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 7.2039e-04 - mae: 0.0100 - mape: 205660.9065\n",
      "Epoch 51/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0097 - mse: 5.5201e-04 - mae: 0.0097 - mape: 144066.0705A: 0s - loss: 0.0097 - mse: 5.3786e-04 - mae: 0.0097 - mape: 142362.826 - ETA: 0s - loss: 0.0097 - mse: 5.4242e-04 - mae: 0.0097 - mape: 142701.20 - ETA: 0s - loss: 0.0097 - mse: 5.4939e-04 - mae: 0.0097 - mape: 143388.404\n",
      "Epoch 52/150\n",
      "178/178 [==============================] - 1s 7ms/step - loss: 0.0103 - mse: 6.3690e-04 - mae: 0.0103 - mape: 175589.6601\n",
      "Epoch 53/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0101 - mse: 6.0346e-04 - mae: 0.0101 - mape: 186667.1014\n",
      "Epoch 54/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0102 - mse: 7.7966e-04 - mae: 0.0102 - mape: 160630.5569\n",
      "Epoch 55/150\n",
      "178/178 [==============================] - 0s 992us/step - loss: 0.0098 - mse: 5.5034e-04 - mae: 0.0098 - mape: 194672.8821\n",
      "Epoch 56/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 7.0308e-04 - mae: 0.0099 - mape: 161664.3378\n",
      "Epoch 57/150\n",
      "178/178 [==============================] - 0s 982us/step - loss: 0.0094 - mse: 5.1310e-04 - mae: 0.0094 - mape: 151021.9697\n",
      "Epoch 58/150\n",
      "178/178 [==============================] - 0s 910us/step - loss: 0.0101 - mse: 8.1667e-04 - mae: 0.0101 - mape: 144761.7931\n",
      "Epoch 59/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0098 - mse: 6.3401e-04 - mae: 0.0098 - mape: 141269.6546\n",
      "Epoch 60/150\n",
      "178/178 [==============================] - 0s 938us/step - loss: 0.0098 - mse: 6.4073e-04 - mae: 0.0098 - mape: 165804.8355\n",
      "Epoch 61/150\n",
      "178/178 [==============================] - 0s 955us/step - loss: 0.0096 - mse: 4.5164e-04 - mae: 0.0096 - mape: 202219.7587\n",
      "Epoch 62/150\n",
      "178/178 [==============================] - 0s 904us/step - loss: 0.0097 - mse: 5.2456e-04 - mae: 0.0097 - mape: 179729.6432\n",
      "Epoch 63/150\n",
      "178/178 [==============================] - 0s 927us/step - loss: 0.0098 - mse: 5.1959e-04 - mae: 0.0098 - mape: 164391.3668\n",
      "Epoch 64/150\n",
      "178/178 [==============================] - 0s 960us/step - loss: 0.0103 - mse: 5.7140e-04 - mae: 0.0103 - mape: 158062.1067\n",
      "Epoch 65/150\n",
      "178/178 [==============================] - 0s 944us/step - loss: 0.0104 - mse: 6.4894e-04 - mae: 0.0104 - mape: 169345.8110\n",
      "Epoch 66/150\n",
      "178/178 [==============================] - 0s 919us/step - loss: 0.0098 - mse: 8.3412e-04 - mae: 0.0098 - mape: 134196.4857\n",
      "Epoch 67/150\n",
      "178/178 [==============================] - 0s 940us/step - loss: 0.0094 - mse: 4.3090e-04 - mae: 0.0094 - mape: 138083.1120\n",
      "Epoch 68/150\n",
      "178/178 [==============================] - 0s 950us/step - loss: 0.0100 - mse: 7.5356e-04 - mae: 0.0100 - mape: 166195.4898\n",
      "Epoch 69/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0097 - mse: 6.9772e-04 - mae: 0.0097 - mape: 155423.4112\n",
      "Epoch 70/150\n",
      "178/178 [==============================] - 0s 985us/step - loss: 0.0096 - mse: 4.5173e-04 - mae: 0.0096 - mape: 150345.8078\n",
      "Epoch 71/150\n",
      "178/178 [==============================] - 0s 931us/step - loss: 0.0098 - mse: 7.6725e-04 - mae: 0.0098 - mape: 134111.9613\n",
      "Epoch 72/150\n",
      "178/178 [==============================] - 0s 995us/step - loss: 0.0100 - mse: 5.4385e-04 - mae: 0.0100 - mape: 149791.7297\n",
      "Epoch 73/150\n",
      "178/178 [==============================] - 0s 925us/step - loss: 0.0098 - mse: 4.8324e-04 - mae: 0.0098 - mape: 139781.9506\n",
      "Epoch 74/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0099 - mse: 6.9201e-04 - mae: 0.0099 - mape: 138379.4024\n",
      "Epoch 75/150\n",
      "178/178 [==============================] - 0s 974us/step - loss: 0.0095 - mse: 5.1868e-04 - mae: 0.0095 - mape: 143097.3516\n",
      "Epoch 76/150\n",
      "178/178 [==============================] - 0s 1ms/step - loss: 0.0094 - mse: 4.9134e-04 - mae: 0.0094 - mape: 153930.8458\n",
      "Epoch 77/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 4.8183e-04 - mae: 0.0097 - mape: 126809.2818\n",
      "Epoch 78/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 6.1425e-04 - mae: 0.0099 - mape: 160225.4665\n",
      "Epoch 79/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 5.6994e-04 - mae: 0.0101 - mape: 144298.9871\n",
      "Epoch 80/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 5.4718e-04 - mae: 0.0100 - mape: 141476.8054\n",
      "Epoch 81/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 5.3290e-04 - mae: 0.0097 - mape: 171245.3280\n",
      "Epoch 82/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 4.7043e-04 - mae: 0.0097 - mape: 139140.7724\n",
      "Epoch 83/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 6.6866e-04 - mae: 0.0099 - mape: 148647.8003\n",
      "Epoch 84/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 5.6409e-04 - mae: 0.0097 - mape: 146576.1265\n",
      "Epoch 85/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.7799e-04 - mae: 0.0096 - mape: 173909.2524\n",
      "Epoch 86/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 5.6294e-04 - mae: 0.0096 - mape: 150914.1995\n",
      "Epoch 87/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 5.4310e-04 - mae: 0.0096 - mape: 165023.7193\n",
      "Epoch 88/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 5.8518e-04 - mae: 0.0100 - mape: 146411.1611\n",
      "Epoch 89/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 6.8428e-04 - mae: 0.0095 - mape: 164459.3520\n",
      "Epoch 90/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 5.9942e-04 - mae: 0.0097 - mape: 150020.5573\n",
      "Epoch 91/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 5.7131e-04 - mae: 0.0097 - mape: 126197.7142\n",
      "Epoch 92/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0096 - mse: 5.2569e-04 - mae: 0.0096 - mape: 135608.5476\n",
      "Epoch 93/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0098 - mse: 5.7619e-04 - mae: 0.0098 - mape: 173857.3845\n",
      "Epoch 94/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0104 - mse: 0.0011 - mae: 0.0104 - mape: 184763.0330\n",
      "Epoch 95/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0098 - mse: 7.4946e-04 - mae: 0.0098 - mape: 142928.1864\n",
      "Epoch 96/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0099 - mse: 5.6253e-04 - mae: 0.0099 - mape: 148566.5407A: 0s - loss: 0.0105 - mse: 7.3475e-04 - mae: 0.0105 - mape: 14\n",
      "Epoch 97/150\n",
      "178/178 [==============================] - 1s 4ms/step - loss: 0.0101 - mse: 7.3561e-04 - mae: 0.0101 - mape: 141691.6763\n",
      "Epoch 98/150\n",
      "178/178 [==============================] - ETA: 0s - loss: 0.0096 - mse: 4.9859e-04 - mae: 0.0096 - mape: 136842.095 - 1s 4ms/step - loss: 0.0096 - mse: 5.0666e-04 - mae: 0.0096 - mape: 137982.4821\n",
      "Epoch 99/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0098 - mse: 6.5895e-04 - mae: 0.0098 - mape: 117598.5867\n",
      "Epoch 100/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0096 - mse: 5.1989e-04 - mae: 0.0096 - mape: 145568.8586\n",
      "Epoch 101/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0103 - mse: 7.6464e-04 - mae: 0.0103 - mape: 150187.3406\n",
      "Epoch 102/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 4.6397e-04 - mae: 0.0095 - mape: 162466.4466\n",
      "Epoch 103/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.7697e-04 - mae: 0.0096 - mape: 122817.0274\n",
      "Epoch 104/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0100 - mse: 7.4727e-04 - mae: 0.0100 - mape: 161477.4829\n",
      "Epoch 105/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 5.2840e-04 - mae: 0.0096 - mape: 148783.2412\n",
      "Epoch 106/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 5.6788e-04 - mae: 0.0097 - mape: 156700.1938\n",
      "Epoch 107/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 6.1766e-04 - mae: 0.0097 - mape: 170077.7463\n",
      "Epoch 108/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 5.9056e-04 - mae: 0.0098 - mape: 151990.8511\n",
      "Epoch 109/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 6.2129e-04 - mae: 0.0097 - mape: 159938.5385\n",
      "Epoch 110/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 5.1185e-04 - mae: 0.0098 - mape: 138877.3238\n",
      "Epoch 111/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 4.3423e-04 - mae: 0.0094 - mape: 173374.9803\n",
      "Epoch 112/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 6.6476e-04 - mae: 0.0101 - mape: 168108.1360\n",
      "Epoch 113/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 6.3823e-04 - mae: 0.0100 - mape: 176647.6738\n",
      "Epoch 114/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 6.1125e-04 - mae: 0.0098 - mape: 110425.8882\n",
      "Epoch 115/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 6.5143e-04 - mae: 0.0098 - mape: 121265.4086\n",
      "Epoch 116/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 7.2067e-04 - mae: 0.0100 - mape: 178773.6064\n",
      "Epoch 117/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 4.8250e-04 - mae: 0.0097 - mape: 161307.7297A: 0s - loss: 0.0099 - mse: 4.8864e-04 - mae: 0.0099 - mape: 18075\n",
      "Epoch 118/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.4468e-04 - mae: 0.0096 - mape: 152757.0261\n",
      "Epoch 119/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.3628e-04 - mae: 0.0096 - mape: 143151.5608\n",
      "Epoch 120/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 5.7748e-04 - mae: 0.0100 - mape: 134006.0653\n",
      "Epoch 121/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 5.2944e-04 - mae: 0.0095 - mape: 154656.2876\n",
      "Epoch 122/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0104 - mse: 7.5275e-04 - mae: 0.0104 - mape: 155913.7364\n",
      "Epoch 123/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0102 - mse: 6.8798e-04 - mae: 0.0102 - mape: 110131.4461\n",
      "Epoch 124/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.8863e-04 - mae: 0.0096 - mape: 135116.0389\n",
      "Epoch 125/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 4.7903e-04 - mae: 0.0094 - mape: 151563.3053\n",
      "Epoch 126/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 7.0140e-04 - mae: 0.0096 - mape: 170409.1812\n",
      "Epoch 127/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 5.6694e-04 - mae: 0.0096 - mape: 173396.0838\n",
      "Epoch 128/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 4.3343e-04 - mae: 0.0096 - mape: 158943.0504\n",
      "Epoch 129/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 5.6438e-04 - mae: 0.0100 - mape: 162130.3014\n",
      "Epoch 130/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 6.0141e-04 - mae: 0.0096 - mape: 162848.4499\n",
      "Epoch 131/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 5.6374e-04 - mae: 0.0100 - mape: 173159.9594\n",
      "Epoch 132/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 5.7464e-04 - mae: 0.0096 - mape: 131918.6132\n",
      "Epoch 133/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0095 - mse: 5.0912e-04 - mae: 0.0095 - mape: 148309.8582\n",
      "Epoch 134/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 5.2001e-04 - mae: 0.0097 - mape: 134760.4879\n",
      "Epoch 135/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0096 - mse: 6.6049e-04 - mae: 0.0096 - mape: 153703.9865\n",
      "Epoch 136/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0098 - mse: 5.9516e-04 - mae: 0.0098 - mape: 158147.2504\n",
      "Epoch 137/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0097 - mse: 5.0889e-04 - mae: 0.0097 - mape: 195382.0973\n",
      "Epoch 138/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 6.1705e-04 - mae: 0.0099 - mape: 147848.5175\n",
      "Epoch 139/150\n",
      "178/178 [==============================] - 0s 3ms/step - loss: 0.0099 - mse: 7.0373e-04 - mae: 0.0099 - mape: 181947.0631\n",
      "Epoch 140/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0099 - mse: 6.2750e-04 - mae: 0.0099 - mape: 144637.2008\n",
      "Epoch 141/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 5.5382e-04 - mae: 0.0096 - mape: 145156.0239\n",
      "Epoch 142/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0097 - mse: 7.4175e-04 - mae: 0.0097 - mape: 121381.3985\n",
      "Epoch 143/150\n",
      "178/178 [==============================] - 1s 3ms/step - loss: 0.0096 - mse: 5.6385e-04 - mae: 0.0096 - mape: 184533.3224A: 0s - loss: 0.0094 - mse: 4.6102e-04 - mae: 0.0094 - mape: 277\n",
      "Epoch 144/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0094 - mse: 4.8683e-04 - mae: 0.0094 - mape: 161730.7465\n",
      "Epoch 145/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.7200e-04 - mae: 0.0096 - mape: 169815.2934\n",
      "Epoch 146/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 8.6825e-04 - mae: 0.0101 - mape: 147921.2414\n",
      "Epoch 147/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.9942e-04 - mae: 0.0096 - mape: 164764.8336\n",
      "Epoch 148/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 4.6283e-04 - mae: 0.0096 - mape: 119071.1803\n",
      "Epoch 149/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0100 - mse: 6.4955e-04 - mae: 0.0100 - mape: 176059.2448\n",
      "Epoch 150/150\n",
      "178/178 [==============================] - 0s 2ms/step - loss: 0.0101 - mse: 7.2910e-04 - mae: 0.0101 - mape: 192443.1177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d177efc8e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training model\n",
    "# regressY_train = regressY_train + 0.000001\n",
    "regressModel.fit(regressX_train, regressY_train, epochs=150, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error:  0.04002769552897978\n",
      "Max Error:  1.3425018652564005\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference of percent growth between prediction and true\n",
      "Total number of entries:  2214\n",
      "<=0.001 diff:        60  Proportion:  2.710027100271003\n",
      "<=0.005 diff:        238  Proportion:  10.749774164408311\n",
      "<=0.1   diff:        321  Proportion:  14.498644986449866\n",
      "<=0.025 diff:        641  Proportion:  28.95212285456188\n",
      "<=0.05  diff:        492  Proportion:  22.22222222222222\n",
      "<=0.10  diff:        290  Proportion:  13.098464317976513\n",
      "<=0.25  diff:        133  Proportion:  6.0072267389340555\n",
      "<=0.50  diff:        27  Proportion:  1.2195121951219512\n",
      ">0.50  diff:        12  Proportion:  0.5420054200542005\n"
     ]
    }
   ],
   "source": [
    "prediction = regressModel.predict(regressX_test)\n",
    "pred = scaler_y.inverse_transform(prediction)\n",
    "true = scaler_y.inverse_transform(regressY_test)\n",
    "# true = true + 0.000001\n",
    "\n",
    "#from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "#print(\"Mean Absolute Percentage Error: \", mape(true, pred))\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "print(\"Mean Absolute Error: \", mae(true, pred))\n",
    "\n",
    "from sklearn.metrics import max_error\n",
    "print(\"Max Error: \", max_error(true, pred))\n",
    "\n",
    "absErrors = abs(true - pred)\n",
    "\n",
    "# making a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(absErrors, bins = 300)\n",
    "plt.show()\n",
    "errorDistribution = []\n",
    "errorDistribution.append(len([i for i in absErrors if  i <= 0.001]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.001 and i <= 0.005]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.005 and i <= 0.01]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.01 and i <= 0.025]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.025 and i <= 0.05]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.05 and i <= 0.1]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.1 and i <= 0.25]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.25 and i <= 0.5]))\n",
    "errorDistribution.append(len([i for i in absErrors if  i > 0.5]))\n",
    "\n",
    "\n",
    "#print(\"Total number of entries: \", len(absErrors))\n",
    "#print(\"0.1% difference:         \", len([i for i in absErrors if  i > 0.001]))\n",
    "#print(\"0.5% difference:         \", len([i for i in absErrors if  i > 0.005]))\n",
    "#print(\"1% difference:           \", len([i for i in absErrors if  i > 0.01]))\n",
    "#print(\"2.5% difference:         \", len([i for i in absErrors if  i > 0.025]))\n",
    "#print(\"5% difference:           \", len([i for i in absErrors if  i > 0.05]))\n",
    "#print(\"10% difference:          \", len([i for i in absErrors if  i > 0.10]))\n",
    "#print(\"25% difference:          \", len([i for i in absErrors if  i > 0.25]))\n",
    "#print(\"50% difference:          \", len([i for i in absErrors if  i > 0.50]))\n",
    "total = len(absErrors)\n",
    "print(\"Difference of percent growth between prediction and true\")\n",
    "print(\"Total number of entries: \", total)\n",
    "print(\"<=0.001 diff:       \", errorDistribution[0], \" Proportion: \", errorDistribution[0]/total * 100)\n",
    "print(\"<=0.005 diff:       \", errorDistribution[1], \" Proportion: \", errorDistribution[1]/total * 100)\n",
    "print(\"<=0.1   diff:       \", errorDistribution[2], \" Proportion: \", errorDistribution[2]/total * 100)\n",
    "print(\"<=0.025 diff:       \", errorDistribution[3], \" Proportion: \", errorDistribution[3]/total * 100)\n",
    "print(\"<=0.05  diff:       \", errorDistribution[4], \" Proportion: \", errorDistribution[4]/total * 100)\n",
    "print(\"<=0.10  diff:       \", errorDistribution[5], \" Proportion: \", errorDistribution[5]/total * 100)\n",
    "print(\"<=0.25  diff:       \", errorDistribution[6], \" Proportion: \", errorDistribution[6]/total * 100)\n",
    "print(\"<=0.50  diff:       \", errorDistribution[7], \" Proportion: \", errorDistribution[7]/total * 100)\n",
    "print(\">0.50  diff:       \", errorDistribution[8], \" Proportion: \", errorDistribution[8]/total * 100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9650cb4e16cdd4a8e8e2d128bf38d875813998db22a3c986335f89e0cb4d7bb2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
